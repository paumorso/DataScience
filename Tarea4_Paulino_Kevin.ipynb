{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción de admisiones estudiantiles con KERAS.\n",
    "\n",
    "## Mi primera red neuronal ?\n",
    "\n",
    "Información de la UCLA basada en 3 datos:\n",
    "\n",
    "   - GRE Scores (Test)\n",
    "   - GPA Scores (Grades)\n",
    "   - Class rank (1-4)\n",
    "\n",
    "El dataset original se encuentra en: http://www.ats.ucla.edu/ y en este mismo apartado corresponde al file *binary.csv* extraido directaemten del sitio.\n",
    "\n",
    "Debe tener instalado en el ambiente de trabajo Pandas, Keras etc.\n",
    "\n",
    "# 1. Carga y vizualización de datos:\n",
    "\n",
    "Para cargar los datos usamos load the data, usaremos un paquete de datos muy útil llamado Pandas. Puede leer en la documentación de Pandas aquí: https://pandas.pydata.org/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     admit  gre   gpa  rank\n",
      "0        0  380  3.61     3\n",
      "1        1  660  3.67     3\n",
      "2        1  800  4.00     1\n",
      "3        1  640  3.19     4\n",
      "4        0  520  2.93     4\n",
      "..     ...  ...   ...   ...\n",
      "395      0  620  4.00     2\n",
      "396      0  560  3.04     3\n",
      "397      0  460  2.63     2\n",
      "398      0  700  3.65     2\n",
      "399      0  600  3.89     3\n",
      "\n",
      "[400 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('https://stats.idre.ucla.edu/stat/data/binary.csv')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1UoQg5oNk7sH"
   },
   "source": [
    "# 2. Procesado de datos:\n",
    "\n",
    "- Se remueven NaNs\n",
    "- One-hot encode con rank\n",
    "- Normalizacion de GRE y GPA, de manera que queden en el rango (0,1)\n",
    "- Se parten los datos en input X - labels y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# remove NaNs\n",
    "data = data.fillna(0)\n",
    "\n",
    "# One-hot encoding the rank\n",
    "processed_data = pd.get_dummies(data, columns=['rank'])\n",
    "\n",
    "# Normalizing the gre and the gpa scores to be in the interval (0,1)\n",
    "processed_data[\"gre\"] = processed_data[\"gre\"]/800\n",
    "processed_data[\"gpa\"] = processed_data[\"gpa\"]/4\n",
    "\n",
    "# Splitting the data input into X, and the labels y \n",
    "X = np.array(processed_data)[:,1:]\n",
    "X = X.astype('float32')\n",
    "y = keras.utils.to_categorical(data[\"admit\"],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (400, 6)\n",
      "\n",
      "Shape of y: (400, 2)\n",
      "\n",
      "First 10 rows of X\n",
      "[[0.475  0.9025 0.     0.     1.     0.    ]\n",
      " [0.825  0.9175 0.     0.     1.     0.    ]\n",
      " [1.     1.     1.     0.     0.     0.    ]\n",
      " [0.8    0.7975 0.     0.     0.     1.    ]\n",
      " [0.65   0.7325 0.     0.     0.     1.    ]\n",
      " [0.95   0.75   0.     1.     0.     0.    ]\n",
      " [0.7    0.745  1.     0.     0.     0.    ]\n",
      " [0.5    0.77   0.     1.     0.     0.    ]\n",
      " [0.675  0.8475 0.     0.     1.     0.    ]\n",
      " [0.875  0.98   0.     1.     0.     0.    ]]\n",
      "\n",
      "First 10 rows of y\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Checking that the input and output look correct\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"\\nShape of y:\", y.shape)\n",
    "print(\"\\nFirst 10 rows of X\")\n",
    "print(X[:10])\n",
    "print(\"\\nFirst 10 rows of y\")\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (400, 6)\n",
      "\n",
      "Shape of y: (400, 2)\n",
      "\n",
      "First 10 rows of X\n",
      "[[0.475  0.9025 0.     0.     1.     0.    ]\n",
      " [0.825  0.9175 0.     0.     1.     0.    ]\n",
      " [1.     1.     1.     0.     0.     0.    ]\n",
      " [0.8    0.7975 0.     0.     0.     1.    ]\n",
      " [0.65   0.7325 0.     0.     0.     1.    ]\n",
      " [0.95   0.75   0.     1.     0.     0.    ]\n",
      " [0.7    0.745  1.     0.     0.     0.    ]\n",
      " [0.5    0.77   0.     1.     0.     0.    ]\n",
      " [0.675  0.8475 0.     0.     1.     0.    ]\n",
      " [0.875  0.98   0.     1.     0.     0.    ]]\n",
      "\n",
      "First 10 rows of y\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Checking that the input and output look correct\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"\\nShape of y:\", y.shape)\n",
    "print(\"\\nFirst 10 rows of X\")\n",
    "print(X[:10])\n",
    "print(\"\\nFirst 10 rows of y\")\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Partición de los datos en training y testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (350, 6)\n",
      "350 train samples\n",
      "50 test samples\n"
     ]
    }
   ],
   "source": [
    "# break training set into training and validation sets\n",
    "(X_train, X_test) = X[50:], X[:50]\n",
    "(y_train, y_test) = y[50:], y[:50]\n",
    "\n",
    "# print shape of training set\n",
    "print('x_train shape:', X_train.shape)\n",
    "\n",
    "# print number of training, validation, and test images\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Definición de la arquitectura de la red neuronal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 128)               896       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 2)                 66        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 11,298\n",
      "Trainable params: 11,298\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(128, input_dim=6))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(.3)) \n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(.2)) \n",
    "\n",
    "model.add(Dense(32))\n",
    "model.add(Activation('linear'))\n",
    "model.add(Dropout(.1))\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss = 'mean_squared_error', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Entrenamiento del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b0a585f488>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "#model.fit(X_train, y_train, epochs=200, batch_size=100, verbose=0)\n",
    "model.fit(X_train, y_train, epochs=500, batch_size=100, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Score del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 46us/step\n",
      "\n",
      " Training Accuracy: 0.7142857139451163\n",
      "50/50 [==============================] - 0s 80us/step\n",
      "\n",
      " Testing Accuracy: 0.6799999976158142\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(X_train, y_train)\n",
    "print(\"\\n Training Accuracy:\", score[1])\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print(\"\\n Testing Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Resumen del análisis efectuado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hiper parámetros de la arquitectura neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se usa una matriz para definir el total de las pruebas a realizar. Se analizan posibles valores para los Hiper parámetros: __Activation__, __Loss__ y __Optimizer__.<br/>\n",
    "\n",
    "Lista de opciones:<br/>\n",
    "Activation: relu, tanh, sigmod y linear<br/>\n",
    "Loss: categorical_crossentropy y mean_squared_error<br/>\n",
    "Optimizer: rmsprop y adam<br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De las anteriores opciones y tomando en cuenta que las opciones de Activation se usaran 3 veces (para cada sub capa), nos dará que la matriz será de 5 x 256. Se presenta un ejemplo de las opciones combinadas que llenan la matriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MatrizHiperParametros = pd.read_csv('MatrizOpcionesHiperParametros.csv')\n",
    "print(MatrizHiperParametros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para hacer las pruebas se toman varios de las combinaciones de la matriz de manera que se reduzca el tiempo invertido y probar la mayor cantidad de combinaciones posibles.<br/>\n",
    "Para este ejercicio se usó también la matriz para generar el código a probar concatenando las diferentes opciones a una plantilla en Excel. Se muestra un ejemplo de lo anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Codigo](https://raw.githubusercontent.com/paumorso/DataSicience/master/CodigoPruebasMatrizHiperParametros.PNG?token=AMVLDGP5I6KHDPXJGPBVEVC5LOEES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con base esta matriz y usando el código de la arquitectura neuronal se procede a ejecutar y obtener los resultados para el entrenamiento y las pruebas del modelo. Se llena esta nueva matriz de resultados para poder comparar los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ID  Trainning  Testing\n",
      "0     1   0.722857     0.66\n",
      "1     2   0.722857     0.68\n",
      "2     3   0.722857     0.68\n",
      "3     4   0.725714     0.68\n",
      "4     5   0.717143     0.66\n",
      "5     6   0.717143     0.62\n",
      "6    28   0.720000     0.66\n",
      "7    74   0.717143     0.66\n",
      "8   108   0.714286     0.66\n",
      "9   114   0.734286     0.66\n",
      "10  132   0.714286     0.66\n",
      "11  151   0.714286     0.66\n",
      "12  172   0.714286     0.66\n",
      "13  212   0.720000     0.66\n",
      "14  228   0.714286     0.68\n",
      "15  235   0.714286     0.64\n",
      "16  244   0.720000     0.64\n",
      "17  253   0.722857     0.66\n",
      "18  256   0.722857     0.66\n"
     ]
    }
   ],
   "source": [
    "ResultadosMatrizHiperParametros = pd.read_csv('ResultadosMatrizOpcionesHiperParametros.csv')\n",
    "print(ResultadosMatrizHiperParametros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados en la matriz se grafican para comparar ambos escenarios tanto en entrenamiento como de pruebas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Grafico](https://raw.githubusercontent.com/paumorso/DataSicience/master/GraficoPruebasMatrizHiperParametros.PNG?token=AMVLDGLFMABGKSM6G6VDH7C5LOEJI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del set de pruebas en la gráfica se selecciona la #15 que corresponde al id #228 de la matriz de opciones, estos son los Hiper parámetros de la arquitectura neuronal que se muestran en este ejemplo en la parte 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al final nuestras pruebas dan que el modelo en el entrenamiento tiene un 71,42% de efectividad y en las pruebas un 67.99%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Luego de la clase se efectúa unos ajustes para mejorar el modelo. Esta es la parte que le comentamos que fuen basado en lo que el Compañero expuso pero el alcanza el 75% en pruebas......"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Se ajusta el conjunto de datos de entrenamiento y pruebas para que sean 80% y 20% respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (320, 6)\n",
      "320 train samples\n",
      "20 test samples\n"
     ]
    }
   ],
   "source": [
    "# break training set into training and validation sets\n",
    "(X_train, X_test) = X[80:], X[:20]\n",
    "(y_train, y_test) = y[80:], y[:20]\n",
    "\n",
    "# print shape of training set\n",
    "print('x_train shape:', X_train.shape)\n",
    "\n",
    "# print number of training, validation, and test images\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. La densidad de las sub capas (excepto la final – que queda igual) se aumentan de manera que queden 512, 128 y 64 respectivamente. Se usan los anteriores Hiper parámetros de la matriz de pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_33 (Dense)             (None, 512)               3584      \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 2)                 130       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 77,634\n",
      "Trainable params: 77,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(512, input_dim=6))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(.3)) \n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(.2)) \n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('linear'))\n",
    "model.add(Dropout(.1))\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss = 'mean_squared_error', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Se modifican los Epochs y los Bacth de la siguiente manera: epochs=1000, batch_size=200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b0a88a8208>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "#model.fit(X_train, y_train, epochs=200, batch_size=100, verbose=0)\n",
    "model.fit(X_train, y_train, epochs=1000, batch_size=200, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Para que al final el modelo se mejora y alcance un 80% en las pruebas, a pesar que en el entrenamiento obtuvo un 71,25%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 0s 678us/step\n",
      "\n",
      " Training Accuracy: 0.71875\n",
      "20/20 [==============================] - 0s 150us/step\n",
      "\n",
      " Testing Accuracy: 0.800000011920929\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(X_train, y_train)\n",
    "print(\"\\n Training Accuracy:\", score[1])\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print(\"\\n Testing Accuracy:\", score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
