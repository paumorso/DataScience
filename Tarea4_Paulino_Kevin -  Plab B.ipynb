{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción de admisiones estudiantiles con KERAS.\n",
    "\n",
    "## Mi primera red neuronal ?\n",
    "\n",
    "Información de la UCLA basada en 3 datos:\n",
    "\n",
    "   - GRE Scores (Test)\n",
    "   - GPA Scores (Grades)\n",
    "   - Class rank (1-4)\n",
    "\n",
    "El dataset original se encuentra en: http://www.ats.ucla.edu/ y en este mismo apartado corresponde al file *binary.csv* extraido directaemten del sitio.\n",
    "\n",
    "Debe tener instalado en el ambiente de trabajo Pandas, Keras etc.\n",
    "\n",
    "# 1. Carga y vizualización de datos:\n",
    "\n",
    "Para cargar los datos usamos load the data, usaremos un paquete de datos muy útil llamado Pandas. Puede leer en la documentación de Pandas aquí: https://pandas.pydata.org/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     admit  gre   gpa  rank\n",
      "0        0  380  3.61     3\n",
      "1        1  660  3.67     3\n",
      "2        1  800  4.00     1\n",
      "3        1  640  3.19     4\n",
      "4        0  520  2.93     4\n",
      "..     ...  ...   ...   ...\n",
      "395      0  620  4.00     2\n",
      "396      0  560  3.04     3\n",
      "397      0  460  2.63     2\n",
      "398      0  700  3.65     2\n",
      "399      0  600  3.89     3\n",
      "\n",
      "[400 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('https://stats.idre.ucla.edu/stat/data/binary.csv')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1UoQg5oNk7sH"
   },
   "source": [
    "# 2. Procesado de datos:\n",
    "\n",
    "- Se remueven NaNs\n",
    "- One-hot encode con rank\n",
    "- Normalizacion de GRE y GPA, de manera que queden en el rango (0,1)\n",
    "- Se parten los datos en input X - labels y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# remove NaNs\n",
    "data = data.fillna(0)\n",
    "\n",
    "# One-hot encoding the rank\n",
    "processed_data = pd.get_dummies(data, columns=['rank'])\n",
    "\n",
    "# Normalizing the gre and the gpa scores to be in the interval (0,1)\n",
    "processed_data[\"gre\"] = processed_data[\"gre\"]/800\n",
    "processed_data[\"gpa\"] = processed_data[\"gpa\"]/4\n",
    "\n",
    "# Splitting the data input into X, and the labels y \n",
    "X = np.array(processed_data)[:,1:]\n",
    "X = X.astype('float32')\n",
    "y = keras.utils.to_categorical(data[\"admit\"],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (400, 6)\n",
      "\n",
      "Shape of y: (400, 2)\n",
      "\n",
      "First 10 rows of X\n",
      "[[0.475  0.9025 0.     0.     1.     0.    ]\n",
      " [0.825  0.9175 0.     0.     1.     0.    ]\n",
      " [1.     1.     1.     0.     0.     0.    ]\n",
      " [0.8    0.7975 0.     0.     0.     1.    ]\n",
      " [0.65   0.7325 0.     0.     0.     1.    ]\n",
      " [0.95   0.75   0.     1.     0.     0.    ]\n",
      " [0.7    0.745  1.     0.     0.     0.    ]\n",
      " [0.5    0.77   0.     1.     0.     0.    ]\n",
      " [0.675  0.8475 0.     0.     1.     0.    ]\n",
      " [0.875  0.98   0.     1.     0.     0.    ]]\n",
      "\n",
      "First 10 rows of y\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Checking that the input and output look correct\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"\\nShape of y:\", y.shape)\n",
    "print(\"\\nFirst 10 rows of X\")\n",
    "print(X[:10])\n",
    "print(\"\\nFirst 10 rows of y\")\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (400, 6)\n",
      "\n",
      "Shape of y: (400, 2)\n",
      "\n",
      "First 10 rows of X\n",
      "[[0.475  0.9025 0.     0.     1.     0.    ]\n",
      " [0.825  0.9175 0.     0.     1.     0.    ]\n",
      " [1.     1.     1.     0.     0.     0.    ]\n",
      " [0.8    0.7975 0.     0.     0.     1.    ]\n",
      " [0.65   0.7325 0.     0.     0.     1.    ]\n",
      " [0.95   0.75   0.     1.     0.     0.    ]\n",
      " [0.7    0.745  1.     0.     0.     0.    ]\n",
      " [0.5    0.77   0.     1.     0.     0.    ]\n",
      " [0.675  0.8475 0.     0.     1.     0.    ]\n",
      " [0.875  0.98   0.     1.     0.     0.    ]]\n",
      "\n",
      "First 10 rows of y\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Checking that the input and output look correct\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"\\nShape of y:\", y.shape)\n",
    "print(\"\\nFirst 10 rows of X\")\n",
    "print(X[:10])\n",
    "print(\"\\nFirst 10 rows of y\")\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Partición de los datos en training y testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (350, 6)\n",
      "350 train samples\n",
      "50 test samples\n"
     ]
    }
   ],
   "source": [
    "# break training set into training and validation sets\n",
    "(X_train, X_test) = X[50:], X[:50]\n",
    "(y_train, y_test) = y[50:], y[:50]\n",
    "\n",
    "# print shape of training set\n",
    "print('x_train shape:', X_train.shape)\n",
    "\n",
    "# print number of training, validation, and test images\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Definición de la arquitectura de la red neuronal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0819 16:53:40.720614 11532 deprecation_wrapper.py:119] From C:\\Users\\PC2\\.conda\\envs\\py3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0819 16:53:40.764584 11532 deprecation_wrapper.py:119] From C:\\Users\\PC2\\.conda\\envs\\py3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0819 16:53:40.767579 11532 deprecation_wrapper.py:119] From C:\\Users\\PC2\\.conda\\envs\\py3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0819 16:53:40.789571 11532 deprecation_wrapper.py:119] From C:\\Users\\PC2\\.conda\\envs\\py3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0819 16:53:40.801558 11532 deprecation.py:506] From C:\\Users\\PC2\\.conda\\envs\\py3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0819 16:53:40.898500 11532 deprecation_wrapper.py:119] From C:\\Users\\PC2\\.conda\\envs\\py3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 66        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 11,298\n",
      "Trainable params: 11,298\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(128, input_dim=6))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(.3)) \n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(.2)) \n",
    "\n",
    "model.add(Dense(32))\n",
    "model.add(Activation('linear'))\n",
    "model.add(Dropout(.1))\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss = 'mean_squared_error', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Entrenamiento del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0819 16:53:41.159337 11532 deprecation_wrapper.py:119] From C:\\Users\\PC2\\.conda\\envs\\py3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b3bcb821c8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "#model.fit(X_train, y_train, epochs=200, batch_size=100, verbose=0)\n",
    "model.fit(X_train, y_train, epochs=500, batch_size=100, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Score del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 211us/step\n",
      "\n",
      " Training Accuracy: 0.7171428568022592\n",
      "50/50 [==============================] - 0s 120us/step\n",
      "\n",
      " Testing Accuracy: 0.6799999976158142\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(X_train, y_train)\n",
    "print(\"\\n Training Accuracy:\", score[1])\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print(\"\\n Testing Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
